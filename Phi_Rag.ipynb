{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec6800c3-51e1-4850-872e-92822f2f9f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86654fa1-1a07-4c02-bca6-22f2c3c81c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f4a67ab-41c5-4920-a510-fe7fdcba1baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the main libraries for setting up code to interact with LLM\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain_huggingface import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60e103f0-d6f2-4c66-95c5-84e4c8a1d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d7c4699-5580-4613-8ca6-aea7b137d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load model in quantized weights to save GPU memory\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_compute_dtype=getattr(torch, \"float16\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19bfa8f7-2141-4c49-8af6-099d976a8381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05df5be232864d289f6e38724536281c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading the model\n",
    "model_name = 'microsoft/phi-2'\n",
    "device = 'cuda:0'\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config, \n",
    "    device_map='auto',\n",
    ")\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a624f5-fedf-4ffc-824d-ca0e54b6273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the pipeline\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    temperature=0.4,\n",
    "    do_sample=True,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.5,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceb2ef8-7784-4855-8572-dfe2f087b2e5",
   "metadata": {},
   "source": [
    "### Test HF pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "508295d8-6a8e-46b3-a06b-c9c8c73c2b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "C:\\Users\\ritap\\anaconda3\\envs\\RAG\\lib\\site-packages\\transformers\\models\\phi\\modeling_phi.py:680: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Which are the top 5 companies in world with their revenue in table format?\\n## INPUT\\nCompany  | Revenue (in billions)\\nApple Inc.| 274,515  \\t   Google LLC     | 182,163    \\t\\t\\tFacebook Holding Company      | 68,932           Microsoft Corporation       | 143 billion            Amazon.com INC         | 386               Other Companies: $1 trillion or more        $2 Trillion+             -                 -$3 Billion                0%-10%              11%-20%, 21%-30%.                                         31%-40%: 41%;41 to 50 % 51 - 60 percent 61 – 70 Percent 71 + Percentage of Top 100 Global Corporations by Total Revenues 2018 Source : Statista; Fortune ; Bloomberg Businessweek'}]\n",
      "CPU times: total: 11.6 s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"Which are the top 5 companies in world with their revenue in table format?\"\n",
    "print(pipeline(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f69b46be-93ca-4415-b5d2-99e8a1a1b68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make sure the model path is correct for your system!\n",
    "# llm = LlamaCpp(\n",
    "#     model_path=r\"C:\\Users\\ritap\\.cache\\lm-studio\\models\\lmstudio-community\\Meta-Llama-3-8B-Instruct-GGUF\\Meta-Llama-3-8B-Instruct-Q4_K_M.gguf\",\n",
    "#     n_gpu_layers=n_gpu_layers, n_batch=n_batch,\n",
    "#     n_ctx = 3000,\n",
    "#     temperature=0.0,\n",
    "#     max_tokens=2000,\n",
    "#     top_p=1,\n",
    "#     callback_manager=callback_manager,\n",
    "#     verbose=True, # Verbose is required to pass to the callback manager\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad0940-ab60-4827-accf-3fe591204a82",
   "metadata": {},
   "source": [
    "### langchain LLM instance from HF pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa6bf9d-4e40-46e4-914c-796d0b205c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline = pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e9fb2-dd8a-4ea7-84df-cff304231f8a",
   "metadata": {},
   "source": [
    "### Test the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93dd9def-71ba-43d7-8271-d2cc7044b849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<====================================== Outcome from model =======================================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which are the top 5 companies in world with their revenue in table format?\n",
      "## INPUT\n",
      "Company  Revenue (in billions) Apple $274.52 Microsoft Azure ($43 billion), Google Cloud Platform, Amazon Web Services and Alibaba Group Holding Limited have been named as a group of five that will be at forefront to deliver on digital transformation for enterprises this year. These were announced by Gartner Inc., which said it expects these firms […] The post Top 10 Companies In World With Their Revenues appeared first... Read More »\n",
      "CPU times: total: 7 s\n",
      "Wall time: 8.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Question for LLM\n",
    "question = \"Which are the top 5 companies in world with their revenue in table format?\"\n",
    "\n",
    "#providing the results\n",
    "print(\"<====================================== Outcome from model =======================================>\")\n",
    "print(llm.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2826c24e-8e85-4b77-bc5e-bb43bc5484f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Callbacks support token-wise streaming\n",
    "# callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "# n_gpu_layers = 1 # Change this value based on your model and your GPU VRAM pool.\n",
    "# n_batch = 4 # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02270e03-8876-4ec7-b89e-f5170abfb6c4",
   "metadata": {},
   "source": [
    "### Making of prompt with Langchain template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc5fb33c-81d9-46ef-a9c8-0e37ddc64303",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Question: {question}\\\n",
    "Answer: Let’s work this out in a step by step way to be sure we have the right answer\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b936b-c1f8-4359-bb75-73a39e60c281",
   "metadata": {},
   "source": [
    "### Making the vector database\n",
    "#### This will be our additional Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "832c0c66-055f-4628-9436-7af01bc1337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USER_AGENT'] = 'myagent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19de1f66-3379-4e9f-8ee2-3f6ca8437adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50464f0b-8264-4059-9ce3-419c8698dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weblink = \"https://www.investopedia.com/biggest-companies-in-the-world-by-market-cap-5212784\"\n",
    "loader = WebBaseLoader(weblink)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df2fe1ac-fda0-4dc8-9346-2984b14ef8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa006f6f-22d8-4912-a9ca-117a5e9f0987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into small chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc50b2fc-ddfc-453e-aeff-a675e84a3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b6457a4-e90e-4e6a-9e3c-3f76730b7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing Embedding\n",
    "from langchain_huggingface import HuggingFaceEmbeddings # other embeddings available \n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "531bfe89-10c8-4bab-be3e-19230ab8e2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritap\\anaconda3\\envs\\RAG\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#storing the data in Vector Store\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e2d714-d3a3-44f9-956f-cffad9116b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
